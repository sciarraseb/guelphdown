---
title: 'Is Timing Everything? Measurement Timing and the Ability to Accurately Model Longitudinal Data'
shorttitle        : "Measurement timing"
author: 'Sebastian L.V. Sciarra'
date: 'October, 2022'
year: '2022'
institution: 'University of Guelph'
advisor: 'David Stanley'
#altadvisor: 'MJ' 
department: 'Psychology'
degree: 'Doctorate of Philosophy'
#field: 'Statistics'
#specialization: 'Statistics'
knit: bookdown::render_book
site: bookdown::bookdown_site
header-includes:

params:
  'Install needed packages for {thesisdown}': True
  
output:
  thesisdown::thesis_pdf: 
    pandoc_args: ["--biblatex"]
    includes:
     after_body: ['80-references.Rmd', '81-appendix.Rmd']
#  thesisdown::thesis_gitbook: default         
#  thesisdown::thesis_word: default
#  thesisdown::thesis_epub: default

# If you are creating a PDF you'll need to write your preliminary content 
# (e.g., abstract, acknowledgements) below or use code similar to line 25-26 
# for the .RMD files. If you are NOT producing a PDF, delete or silence
# lines 25-39 in this YAML header.
abstract: '`r if(knitr:::is_latex_output()) paste(readLines(here::here("prelims", "00-abstract.Rmd")), collapse = "\n  ")`'
# If you'd rather include the preliminary content in files instead of inline
# like below, use a command like that for the abstract above.  Note that a tab 
# is needed on the line after the `|`.
acknowledgements: |
 [To  be completed after defense]
dedication: |
  [To  be completed after defense]
#  
#   You can have a dedication here if you wish. You can have a dedication here if you wish.You can have a #dedication here if you wish.You can have a dedication here if you wish.You can have a dedication here if you #wish.You ca
preface: |
  This is an example of a thesis setup to use the Ã¥reed thesis document class 
  (for LaTeX) and the R bookdown package, in general.
#abbreviations:
#  ABC: American Broadcasting Company
#  CBS: Colombia Broadcasting System
#  CUS: Computer User Services
#  PBS: Public Broadcasting System
# Specify the location of the bibliography below
bibliography: bib/references.bib
# Download your specific csl file and refer to it in the line below.
#csl: csl/apa.csl
lot: true  #list of tables 
lof: true  #list of figures
loa: true  #list of appendices
toc-depth: '5' #header level depth for table of contents
linenumbers: true #whether to put linenumbers in text (effective when making drafts of dissertation)
draft: true #prints 'DRAFT' watermark on pages (useful when making drafts)
ArialFont: false #Times New Roman set as default if false
fontsize: '12pt' #options: 10pt, 11pt, or 12pt (does not have to be wrapped in quotation marks)
linespacing: 2
backref: true #include backreferences
linkcolor: blue #color of all hyperlinks; set to black for print 
print: false #creates print version of thesis with blank pages in preamble
print_refs: true #prints references (useful when drafting); use in conjunction with knit_exit() to stop rendering at any point 
---

<!--
Above is the YAML (YAML Ain't Markup Language) header that includes a lot of 
metadata used to produce the document.  Be careful with spacing in this header!

If you'd prefer to not include a Dedication, for example, simply delete the section entirely, or silence them (add # before each line). 

If you have other LaTeX packages you would like to include, delete the # before header-includes and list the packages after hyphens on new lines.

If you'd like to include a comment that won't be produced in your resulting file enclose it in a block like this.

If you receive a duplicate label error after knitting, make sure to delete the index.Rmd file and then knit again.
-->
```{r package_loading_int, include=F}
#load packages
#devtools::install_github(repo = 'sciarraseb/nonlinSimsAnalysis', force = T)
library(easypackages)
packages <- c('devtools','tidyverse', 'RColorBrewer', 'parallel', 'data.table', 'kableExtra', 'ggtext', 'egg', 'ggbrace', 'cowplot', 'nonlinSimsAnalysis', 'nonlinSims', 'knitr')
libraries(packages)
knitr::opts_chunk$set(message = F)
#options(tinytex.compile.min_times = 3)
write_bib(x = packages, file = 'bib/references.bib') #run code once for including packages in .bib file 
```


```{r knitting_setup_int, echo=F, message = F, warning = F}
#import raw data files (needed for computing variances)
exp_1_raw <- nonlinSimsAnalysis:::convert_raw_var_to_sd(raw_data = read_csv('data/exp_1_data.csv')) %>%
  mutate_at(.vars = c("number_measurements", "measurement_spacing", "midpoint"), factor)

exp_2_raw <-nonlinSimsAnalysis:::convert_raw_var_to_sd(raw_data = read_csv('data/exp_2_data.csv')) %>%
  mutate_at(.vars = c("number_measurements", "measurement_spacing", "sample_size"), factor)

exp_3_raw <-nonlinSimsAnalysis:::convert_raw_var_to_sd(raw_data = read_csv('data/exp_3_data.csv')) %>%
  mutate_at(.vars = c("number_measurements", "time_structuredness", "sample_size"), factor)

exp_3_def_raw <-nonlinSimsAnalysis:::convert_raw_var_to_sd(raw_data = read_csv('data/exp_3_def.csv')) %>%
  mutate_at(.vars = c("number_measurements", "time_structuredness", "sample_size"), factor)


#unfiltered data 
param_summary_exp_1 <- readRDS(file = 'data/uf_param_summary_exp_1.RData')
param_summary_exp_2 <- readRDS(file = 'data/uf_param_summary_exp_2.RData')
param_summary_exp_3 <- readRDS(file = 'data/uf_param_summary_exp_3.RData')
param_summary_exp_3_def <- readRDS(file = 'data/uf_param_summary_exp_3_def.RData')

#create analytical versions of summary data + converts vars to sds
exp_1_analytical <- generate_likert_days_data_sets(summary_data = param_summary_exp_1, exp_num = '1')
exp_2_analytical <- generate_likert_days_data_sets(summary_data = param_summary_exp_2, exp_num = '2')
exp_3_analytical <- generate_likert_days_data_sets(summary_data = param_summary_exp_3, exp_num = '3')
exp_3_def_analytical <- generate_likert_days_data_sets(summary_data = param_summary_exp_3_def, exp_num = '3')
exp_3_def_analytical$days$time_structuredness <-  factor(x = 'slow_response',labels = 'Time unstructured (slow response)')
exp_3_def_analytical$likert$time_structuredness <-  factor(x = 'slow_response',labels = 'Time unstructured (slow response)')

combined_analytical_exp_1 <- rbind(exp_1_analytical$likert, exp_1_analytical$days)
combined_analytical_exp_2 <- rbind(exp_2_analytical$likert, exp_2_analytical$days)
combined_analytical_exp_3 <- rbind(exp_3_analytical$likert, exp_3_analytical$days)
combined_analytical_exp_3_def <- rbind(exp_3_def_analytical$likert, exp_3_def_analytical$days)


#create condition summary data sets 
cond_summary_exp_1 <- compute_condition_summary(param_summary_data = combined_analytical_exp_1, facet_var = 'measurement_spacing', 
                          ind_vars = c('number_measurements', 'measurement_spacing', 'midpoint'))
cond_summary_exp_2 <- compute_condition_summary(param_summary_data = combined_analytical_exp_2, facet_var = 'measurement_spacing', 
                  ind_vars = c('number_measurements', 'measurement_spacing', 'sample_size'))

cond_summary_exp_3 <- compute_condition_summary(param_summary_data = combined_analytical_exp_3, facet_var = 'time_structuredness', 
                          ind_vars = c('number_measurements', 'sample_size', 'time_structuredness'))


cond_summary_exp_3_def <- compute_condition_summary(param_summary_data = combined_analytical_exp_3_def, facet_var = 'time_structuredness', 
                          ind_vars = c('number_measurements', 'sample_size', 'time_structuredness'))

```

```{r pre_knitting_setup_unfiltered_int, echo=F, eval=F, include=F}
#code should be computed before knitting to decrease knitting time 
#load data from experiments
exp_1 <- read_csv(file = 'data/exp_1_data.csv') %>% filter(code == 0)
exp_2 <- read_csv(file = 'data/exp_2_data.csv')
exp_3 <- read_csv(file = 'data/exp_3_data.csv')
exp_3_def <- read_csv(file = 'data/exp_3_def.csv')


#compute parameter summary statistics  
exp_1_long <- exp_1 %>%
    filter(code == 0) %>%
    #place parameter estimates in one column
    pivot_longer(cols = contains(c('theta', 'alpha', 'beta', 'gamma', 'epsilon')),
                 names_to = 'parameter', values_to = 'estimate') %>%
    filter(parameter == 'beta_fixed') %>%
    mutate(pop_value = midpoint)

exp_1_ordered <- order_param_spacing_levels(data = exp_1_long)

param_summary_exp_1 <- compute_parameter_summary(data = exp_1, exp_num = 1)
param_summary_exp_2 <- compute_parameter_summary(data = exp_2, exp_num = 2)
param_summary_exp_3 <- compute_parameter_summary(data = exp_3, exp_num = 3)
param_summary_exp_3_def <- compute_parameter_summary(data = exp_3_def, exp_num = 2)

#necessary factor conversions 
param_summary_exp_1$number_measurements <- factor(param_summary_exp_1$number_measurements, levels = c(5, 7, 9,11))
param_summary_exp_1$midpoint <- factor(param_summary_exp_1$midpoint, levels = c(80, 180,280))

param_summary_exp_2$number_measurements <- factor(param_summary_exp_2$number_measurements, levels = c(5, 7, 9,11))
param_summary_exp_2$sample_size <- factor(param_summary_exp_2$sample_size, levels = c(30, 50, 100, 200, 500, 1000))

param_summary_exp_3$number_measurements <- factor(param_summary_exp_3$number_measurements, levels = c(5, 7, 9,11))
param_summary_exp_3$sample_size <- factor(param_summary_exp_3$sample_size, levels = c(30, 50, 100, 200, 500, 1000))

#write data sets 
#save parameter summary files as RData files so that metadata are correctly stored (e.g., factor levels, variable types)
saveRDS(object = param_summary_exp_1, file = 'data/uf_param_summary_exp_1.RData')
saveRDS(object = param_summary_exp_2, file = 'data/uf_param_summary_exp_2.RData')
saveRDS(object = param_summary_exp_3, file = 'data/uf_param_summary_exp_3.RData')
```
\nocite{R-nonlinSimsAnalysis}
`r knit_exit()`
